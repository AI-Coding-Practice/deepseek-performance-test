# 大模型性能测试框架设计（单机版）

## 1. 系统架构

### 1.1 整体架构
```
+------------------+     +------------------+
|   负载生成器     |     |   性能监控器     |
| Load Generator   | --> | Performance      |
| (Ollama Client)  |     | Monitor         |
+------------------+     +------------------+
        |                        |
        v                        v
+------------------+     +------------------+
|   Ollama服务     |     |   数据收集器     |
| Ollama Service   | <-- | Data Collector   |
+------------------+     +------------------+
```

### 1.2 核心组件
1. 负载生成器 (Load Generator)
   - 支持动态调整QPS (10-500)
   - 支持自定义输入Token长度 (1000-4096)
   - 支持多种并发模式
   - 支持自定义提示词模板
   - 使用Python的asyncio实现异步并发
   - 集成Ollama API客户端

2. 性能监控器 (Performance Monitor)
   - 首Token响应时间监控
   - 平均推理速度监控
   - P50/P90/P95/P99延迟监控
   - GPU使用率监控（使用nvidia-smi或pynvml）
   - GPU显存占用监控
   - CPU使用率监控（使用psutil）
   - 内存使用率监控
   - 实时性能指标计算和展示

3. 数据收集器 (Data Collector)
   - 实时数据采集
   - 数据存储（CSV/JSON格式）
   - 数据预处理
   - 测试结果导出
   - 性能指标统计

## 2. 性能指标

### 2.1 核心指标
1. 响应时间指标
   - 首Token响应时间 (First Token Latency)
   - P50/P90/P95/P99延迟
   - 平均响应时间
   - 最大/最小响应时间

2. 吞吐量指标
   - 平均推理速度 (tokens/sec)
   - 请求速率 (requests/sec)
   - 最大QPS支持
   - 并发请求处理能力

3. 资源利用率
   - GPU使用率
   - GPU显存占用率
   - CPU使用率
   - 内存使用率

### 2.2 稳定性指标
1. 错误率
   - 请求失败率
   - 超时率
   - 异常响应率

2. 系统稳定性
   - 服务可用性
   - 资源使用稳定性
   - 性能波动情况

## 3. 测试场景

### 3.1 负载测试
1. QPS阶梯测试
   - 10 QPS → 50 QPS → 100 QPS → 200 QPS → 500 QPS
   - 每个阶梯持续5分钟
   - 记录性能指标变化

2. Token长度测试
   - 1000 tokens → 2048 tokens → 4096 tokens
   - 固定QPS下测试
   - 记录资源消耗变化

### 3.2 稳定性测试
1. 长时间运行测试
   - 持续运行24小时
   - 监控系统稳定性
   - 记录性能衰减情况

2. 极限测试
   - 最大QPS测试
   - 最大Token长度测试
   - 资源耗尽测试

## 4. 技术实现

### 4.1 开发语言和框架
- Python 3.8+
- asyncio (异步并发)
- psutil (系统资源监控)
- pynvml (GPU监控)
- pandas (数据处理)
- matplotlib (数据可视化)
- Ollama API (模型服务接口)

### 4.2 数据存储
- CSV/JSON/HTML格式存储测试数据
- 本地文件系统存储
- 测试结果目录结构：
  ```
  test_results/
  ├── test_YYYYMMDD_HHMMSS/          # 每次测试的独立目录
  │   ├── model_responses/           # 模型响应数据目录
  │   ├── load_test_results.csv      # 负载测试详细结果
  │   ├── performance_metrics.csv    # 性能指标数据
  │   ├── performance_stats.json     # 性能统计数据
  │   ├── performance_charts.html    # 性能图表
  │   ├── test_report.html          # HTML格式测试报告
  │   └── test_report.json          # JSON格式测试报告
  performance_reports/           # 性能报告汇总目录
      └── performance_report_YYYYMMDD_HHMMSS.json  # 性能报告
  ```

### 4.3 代码结构
```
performance_test/
├── load_generator/          # 负载生成器模块
│   └── generator.py        # 负载生成器核心实现，包含提示词模板管理
├── monitor/                # 性能监控模块
│   └── performance.py     # 性能指标监控和系统资源监控
├── collector/             # 数据收集模块
│   └── data.py           # 数据收集、存储和可视化
└── main.py               # 主程序入口
```

## 5. 测试流程

1. 环境准备
   - 安装依赖包
   - 配置测试参数
   - 准备测试数据

2. 基准测试
   - 单请求测试
   - 小规模并发测试
   - 资源基准测试

3. 负载测试
   - QPS阶梯测试
   - Token长度测试
   - 混合负载测试

4. 稳定性测试
   - 长时间运行测试
   - 极限测试
   - 故障恢复测试

5. 数据分析
   - 性能指标分析
   - 瓶颈分析
   - 优化建议

## 6. 输出报告

### 6.1 实时监控
- 控制台实时性能指标展示
- 资源使用监控
- 告警信息

### 6.2 测试报告
- 性能测试结果（CSV/JSON）
- 稳定性测试结果
- 优化建议

### 6.3 分析报告
- 性能指标图表
- 资源使用分析
- 优化方案建议 